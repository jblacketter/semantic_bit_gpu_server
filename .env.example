# Semantic Bit GPU Server Configuration
# Copy this to .env and customize

# Server Settings
HOST=0.0.0.0
PORT=8000
RELOAD=false

# Model Settings
MODEL_ID=runwayml/stable-diffusion-v1-5
DEVICE=cuda
TORCH_DTYPE=float16

# Generation Defaults (Codex Recommendations)
DEFAULT_STEPS=28
DEFAULT_GUIDANCE_SCALE=7.0
DEFAULT_HEIGHT=512
DEFAULT_WIDTH=512

# Scheduler Settings
SCHEDULER_TYPE=DPMSolver++
USE_KARRAS_SIGMAS=true

# Performance Settings
OFFLINE_MODE=false
LOCAL_FILES_ONLY=false
MAX_CONCURRENT_REQUESTS=2
REQUEST_TIMEOUT=60
